# SpinePrep Snakefile: validate + discover + mppca + motion + confounds smoke
import json
import os
import subprocess
import sys
from pathlib import Path

SYS_ROOT = Path(__file__).resolve().parents[1]
if str(SYS_ROOT) not in sys.path:
    sys.path.insert(0, str(SYS_ROOT))

from workflow.lib.samples import first_row, rows, row_by_id  # type: ignore
from workflow.lib.samples import rows as _rows  # type: ignore
from workflow.lib.deriv import derive_paths, stage_file  # type: ignore
from workflow.lib.provenance import write_prov  # type: ignore
from workflow.lib.qc import subjects_from_manifest, render_subject_report  # type: ignore
from workflow.lib.registration import derive_inputs, derive_outputs  # type: ignore
from workflow.lib.crop import detect_crop, write_crop_json  # type: ignore

CFG_PATH = os.environ.get("SPINEPREP_CONFIG", "configs/study.yaml")
CFG_SCHEMA = "schemas/config.schema.json" if Path("schemas/config.schema.json").exists() else None


def _load():
    from spineprep.config import load_config

    return load_config(CFG_PATH, CFG_SCHEMA)


CFG = _load()
BIDS = CFG["paths"]["bids_dir"]
DERIV = CFG["paths"]["deriv_dir"]
LOGS = CFG["paths"]["logs_dir"]
Path(LOGS).mkdir(parents=True, exist_ok=True)

SAMPLES = f"{LOGS}/samples.tsv"
MANIFEST_DERIV = f"{LOGS}/manifest_deriv.tsv"
# Load rows only if files exist (for startup)
try:
    SAMPLE_ROWS = rows(SAMPLES) if Path(SAMPLES).exists() else []
    DERIV_ROWS = rows(MANIFEST_DERIV) if Path(MANIFEST_DERIV).exists() else []
    N = len(DERIV_ROWS)
    SUBS = subjects_from_manifest(MANIFEST_DERIV) if Path(MANIFEST_DERIV).exists() else []
except Exception:
    SAMPLE_ROWS = []
    DERIV_ROWS = []
    N = 0
    SUBS = []


rule all:
    input:
        f"{LOGS}/validate.ok",
        f"{LOGS}/discover.json",
        f"{LOGS}/samples.tsv",
        f"{LOGS}/manifest_deriv.tsv",  # <-- add this
        # Preprocessing targets (confounds for all runs)
        expand(
            f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-confounds_timeseries.tsv",
            sub=[row_by_id(SAMPLES, i)["sub"] for i in range(N)],
            task=[row_by_id(SAMPLES, i)["task"] for i in range(N)],
            run=[row_by_id(SAMPLES, i)["run"] for i in range(N)],
        )
        if N > 0
        else [],
        expand(
            f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-confounds_timeseries.json",
            sub=[row_by_id(SAMPLES, i)["sub"] for i in range(N)],
            task=[row_by_id(SAMPLES, i)["task"] for i in range(N)],
            run=[row_by_id(SAMPLES, i)["run"] for i in range(N)],
        )
        if N > 0
        else [],
        # QC reports (one per subject)
        expand(
            f"{DERIV}/{{sub}}/reports/{{sub}}_desc-qc.html",
            sub=subjects_from_manifest(MANIFEST_DERIV) if N > 0 else [],
        ),
        # Registration targets (conditional, mask outputs)
        expand(
            "{cordmask_pam50}",
            cordmask_pam50=(
                [
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["mask_pam50_cord"]
                    for i in range(N)
                ]
                if N > 0
                else []
            ),
        )
        if CFG.get("registration", {}).get("enable", False)
        else [],


rule validate_config:
    output:
        ok=f"{LOGS}/validate.ok",
    run:
        from spineprep.config import load_config

        load_config(CFG_PATH, CFG_SCHEMA)
        Path(output.ok).write_text("ok\n")


rule discover:
    input:
        ok=rules.validate_config.output.ok,
    output:
        out=f"{LOGS}/discover.json",
    run:
        from spineprep.config import load_config
        from spineprep.adapters.bids import discover

        cfg = load_config(CFG_PATH, CFG_SCHEMA)
        summary = discover(cfg["paths"]["bids_dir"])
        Path(output.out).write_text(json.dumps(summary, indent=2))
        print(
            "Subjects:",
            summary["counts"]["subjects"],
            "Runs:",
            summary["counts"]["runs"],
        )


rule samples:
    input:
        disc=rules.discover.output.out,
    output:
        tsv=f"{LOGS}/samples.tsv",
    run:
        from workflow.lib.samples import build_samples, assign_motion_groups  # type: ignore
        from spineprep.config import load_config

        # Build samples first
        n = build_samples(input.disc, BIDS, output.tsv)

        # Load config and assign motion groups
        cfg = load_config(CFG_PATH, CFG_SCHEMA)
        concat_mode = (
            cfg.get("options", {}).get("motion", {}).get("concat", {}).get("mode", "session+task")
        )
        require_same = (
            cfg.get("options", {}).get("motion", {}).get("concat", {}).get("require_same", [])
        )

        # Read samples and assign motion groups
        rows = _rows(output.tsv)
        rows_with_groups = assign_motion_groups(rows, concat_mode, require_same)

        # Write updated samples with motion groups
        import csv

        with open(output.tsv, "w", newline="") as f:
            if rows_with_groups:
                w = csv.DictWriter(f, fieldnames=list(rows_with_groups[0].keys()), delimiter="\t")
                w.writeheader()
                for r in rows_with_groups:
                    w.writerow(r)

        print(f"Wrote samples.tsv with {n} rows and motion groups")


rule manifest_deriv:
    input:
        samples=SAMPLES,
    output:
        tsv=f"{LOGS}/manifest_deriv.tsv",
    run:
        import csv, json
        from spineprep.config import load_config

        cfg = load_config(CFG_PATH, CFG_SCHEMA)
        deriv_root = cfg["paths"]["deriv_dir"]
        rows = _rows(input.samples)
        out_fields = None
        with open(output.tsv, "w", newline="") as f:
            # write original cols + derivative cols
            # grab a header from first row
            if not rows:
                # write only header if empty
                base_fields = []
            else:
                base_fields = list(rows[0].keys())
            deriv_fields = [
                "deriv_mppca",
                "deriv_motion",
                "deriv_motion_params_tsv",
                "deriv_motion_params_json",
                "deriv_confounds_tsv",
                "deriv_confounds_json",
            ]
            out_fields = base_fields + deriv_fields
            w = csv.DictWriter(f, fieldnames=out_fields, delimiter="\t")
            w.writeheader()
            for r in rows:
                r2 = dict(r)
                r2.update(derive_paths(r, deriv_root))
                w.writerow(r2)
        print(f"Wrote manifest_deriv.tsv with {len(rows)} rows")


rule preproc_all:
    input:
        manifest=MANIFEST_DERIV,
        # all confounds derivatives for every row (TSV & JSON)
        confounds_tsv=(
            expand(
                f"{DERIV}/sub-{{sub}}/func/sub-{{sub}}_task-{{task}}_run-{{run}}_desc-confounds_timeseries.tsv",
                sub=[row_by_id(SAMPLES, i)["sub"] for i in range(N)],
                task=[row_by_id(SAMPLES, i)["task"] for i in range(N)],
                run=[row_by_id(SAMPLES, i)["run"] for i in range(N)],
            )
            if N > 0
            else []
        ),
        confounds_json=(
            expand(
                f"{DERIV}/sub-{{sub}}/func/sub-{{sub}}_task-{{task}}_run-{{run}}_desc-confounds_timeseries.json",
                sub=[row_by_id(SAMPLES, i)["sub"] for i in range(N)],
                task=[row_by_id(SAMPLES, i)["task"] for i in range(N)],
                run=[row_by_id(SAMPLES, i)["run"] for i in range(N)],
            )
            if N > 0
            else []
        ),


# Per-run MP-PCA
rule mppca:
    input:
        manifest=SAMPLES,
    output:
        bold=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-mppca_bold.nii.gz",
    log:
        f"{LOGS}/mppca_{{sub}}_{{task}}_{{run}}.log",
    resources:
        mem_mb=500,
    run:
        import os, subprocess
        from pathlib import Path as _P

        # Get run info for this wildcard
        r = find_row_by_wildcards(wildcards.sub, wildcards.task, wildcards.run)

        env = os.environ.copy()
        env["IN_BOLD"] = r["bold_path"]
        env["DENOISE_MPPCA"] = "1" if CFG.get("options", {}).get("denoise_mppca", False) else "0"
        Path("steps/spi05_mppca.sh").chmod(0o755)
        subprocess.run(["bash", "steps/spi05_mppca.sh"], check=True, env=env)
        # Stage to derivatives
        stage_file(r["mppca_path"], output.bold)
        # Provenance
        write_prov(
            target=output.bold,
            step="mppca",
            inputs={"IN_BOLD": r["bold_path"]},
            params={"denoise_mppca": CFG.get("options", {}).get("denoise_mppca", False)},
            tools={"step": "spi05_mppca.sh"},
        )


# Grouped motion correction (concatenate → SCT → split)
rule motion_concat_group:
    input:
        # Input files will be determined dynamically based on motion_group
        lambda wildcards: [
            (
                row_by_id(SAMPLES, i)["mppca_path"]
                if Path(row_by_id(SAMPLES, i)["mppca_path"]).exists()
                else row_by_id(SAMPLES, i)["bold_path"]
            )
            for i in range(N)
            if row_by_id(SAMPLES, i).get("motion_group", "").startswith(wildcards.group)
        ],
    output:
        group_bold=f"{DERIV}/motion_groups/{{group}}/group_desc-motioncorr_bold.nii.gz",
        group_params=f"{DERIV}/motion_groups/{{group}}/group_desc-motion_params.tsv",
        group_index=f"{DERIV}/motion_groups/{{group}}/group.index.json",
        group_prov=f"{DERIV}/motion_groups/{{group}}/group_motion.prov.json",
    run:
        import os, subprocess, json
        from pathlib import Path as _P

        # Get motion configuration
        motion_engine = CFG.get("options", {}).get("motion", {}).get("engine", "sct+rigid3d")
        slice_axis = CFG.get("options", {}).get("motion", {}).get("slice_axis", "IS")
        concat_mode = (
            CFG.get("options", {}).get("motion", {}).get("concat", {}).get("mode", "session+task")
        )

        # Find all runs in this group
        group_runs = []
        for i in range(N):
            r = row_by_id(SAMPLES, i)
            if r.get("motion_group", "").startswith(wildcards.group):
                group_runs.append((i, r))

        if not group_runs:
            # No runs in this group, create empty outputs
            Path(output.group_bold).parent.mkdir(parents=True, exist_ok=True)
            Path(output.group_bold).touch()
            Path(output.group_params).touch()
            Path(output.group_index).write_text("{}")
            Path(output.group_prov).write_text("{}")
            return

            # Prepare input files and index mapping
        input_files = []
        index_map = {}
        frame_offset = 0

        for run_idx, (i, r) in enumerate(group_runs):
            in_bold = r["mppca_path"] if _P(r["mppca_path"]).exists() else r["bold_path"]
            input_files.append(in_bold)

            # Get number of volumes in this run
            try:
                nvols = int(subprocess.check_output(["fslval", in_bold, "dim4"], text=True).strip())
            except (subprocess.CalledProcessError, FileNotFoundError):
                nvols = 100  # Fallback

                # Create frame range for this run
            frames = list(range(frame_offset, frame_offset + nvols))
            index_map[str(run_idx)] = frames
            frame_offset += nvols

            # Create group index file
        Path(output.group_index).parent.mkdir(parents=True, exist_ok=True)
        with open(output.group_index, "w") as f:
            json.dump(index_map, f, indent=2)

            # Run grouped motion correction
        env = os.environ.copy()
        env["IN_BOLD"] = input_files[0]  # Primary input
        env["OUT_BOLD"] = output.group_bold
        env["OUT_PARAMS_TSV"] = output.group_params
        env["OUT_PARAMS_JSON"] = output.group_bold.replace(".nii.gz", "_params.json")
        env["MOTION_ENGINE"] = "group"
        env["SLICE_AXIS"] = slice_axis
        env["GROUP_INPUTS"] = json.dumps(input_files)
        env["GROUP_INDEX"] = output.group_index

        Path("steps/spi06_motion.sh").chmod(0o755)
        subprocess.run(["bash", "steps/spi06_motion.sh"], check=True, env=env)

        # Write group provenance
        prov_data = {
            "step": "motion_concat_group",
            "group": wildcards.group,
            "n_runs": len(group_runs),
            "engine": motion_engine,
            "slice_axis": slice_axis,
            "concat_mode": concat_mode,
            "timestamp": subprocess.check_output(["date", "-Iseconds"], text=True).strip(),
        }
        with open(output.group_prov, "w") as f:
            json.dump(prov_data, f, indent=2)


# Temporal crop detection (per-run wildcard rule)
rule crop_detect:
    input:
        bold=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-mppca_bold.nii.gz",
    output:
        crop_json=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-crop.json",
    log:
        f"{LOGS}/crop_detect_{{sub}}_{{task}}_{{run}}.log",
    resources:
        mem_mb=200,
    run:
        import os
        from pathlib import Path as _P

        # Get temporal crop configuration
        crop_enabled = CFG.get("options", {}).get("temporal_crop", {}).get("enable", True)
        crop_method = (
            CFG.get("options", {}).get("temporal_crop", {}).get("method", "cord_mean_robust_z")
        )
        max_trim_start = CFG.get("options", {}).get("temporal_crop", {}).get("max_trim_start", 10)
        max_trim_end = CFG.get("options", {}).get("temporal_crop", {}).get("max_trim_end", 10)
        z_thresh = CFG.get("options", {}).get("temporal_crop", {}).get("z_thresh", 2.5)

        # Get run info
        r = row_by_id(SAMPLES, int(wildcards.id))

        # Determine input file (prefer mppca if available)
        in_bold = input.bold

        # Check for cord mask (if registration is enabled)
        cord_mask = None
        if CFG.get("registration", {}).get("enable", False):
            # Look for cord mask from registration
            cord_mask_path = f"{DERIV}/sub-{wildcards.sub}/func/sub-{wildcards.sub}_task-{wildcards.task}_run-{wildcards.run}_space-native_desc-cordmask-seg.nii.gz"
            if Path(cord_mask_path).exists():
                cord_mask = cord_mask_path

                # Run crop detection
        crop_opts = {
            "enable": crop_enabled,
            "method": crop_method,
            "max_trim_start": max_trim_start,
            "max_trim_end": max_trim_end,
            "z_thresh": z_thresh,
        }

        crop_info = detect_crop(
            confounds_tsv=r.get("confounds_tsv"),
            bold_path=in_bold,
            cord_mask=cord_mask,
            opts=crop_opts,
        )

        # Write crop JSON
        write_crop_json(output.crop_json, crop_info)


# Per-run motion (depends on mppca output or falls back)
rule motion:
    input:
        manifest=MANIFEST_DERIV,
        crop_json=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-crop.json",
        mppca=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-mppca_bold.nii.gz",
    output:
        bold=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-motion_bold.nii.gz",
        params_tsv=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-motion_params.tsv",
        params_json=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-motion_params.json",
    log:
        f"{LOGS}/motion_{{sub}}_{{task}}_{{run}}.log",
    resources:
        mem_mb=1000,
    run:
        import os, subprocess, json
        from pathlib import Path as _P

        # Get motion configuration
        motion_engine = CFG.get("options", {}).get("motion", {}).get("engine", "sct+rigid3d")
        slice_axis = CFG.get("options", {}).get("motion", {}).get("slice_axis", "IS")

        # Get run info for this wildcard
        r = find_row_by_wildcards(wildcards.sub, wildcards.task, wildcards.run)
        in_bold = input.mppca

        # Per-run motion correction
        log(
            f"Running per-run motion correction for run {wildcards.sub}_{wildcards.task}_{wildcards.run}"
        )

        # Read crop information from input
        crop_from = 0
        crop_to = 0
        if Path(input.crop_json).exists():
            with open(input.crop_json, "r") as f:
                crop_info = json.load(f)
                crop_from = crop_info.get("from", 0)
                crop_to = crop_info.get("to", 0)

        env = os.environ.copy()
        env["IN_BOLD"] = in_bold
        env["OUT_BOLD"] = output.bold
        env["OUT_PARAMS_TSV"] = output.params_tsv
        env["OUT_PARAMS_JSON"] = output.params_json
        env["MOTION_ENGINE"] = motion_engine
        env["SLICE_AXIS"] = slice_axis
        env["CROP_FROM"] = str(crop_from)
        env["CROP_TO"] = str(crop_to)

        Path("steps/spi06_motion.sh").chmod(0o755)
        subprocess.run(["bash", "steps/spi06_motion.sh"], check=True, env=env)

        # Stage files into derivatives (already done by the script, but ensure they exist)
        stage_file(r["motion_path"], output.bold)
        stage_file(r["motion_params_tsv"], output.params_tsv)
        stage_file(r["motion_params_json"], output.params_json)

        write_prov(
            target=output.bold,
            step="motion",
            inputs={"IN_BOLD": in_bold, "CROP_JSON": input.crop_json},
            params={
                "engine": motion_engine,
                "slice_axis": slice_axis,
                "temporal_crop": {
                    "from": crop_from,
                    "to": crop_to,
                    "source": "desc-crop.json",
                },
            },
            tools={"step": "spi06_motion.sh"},
        )


# Per-run confounds (depends on motion output or falls back)
def find_row_by_wildcards(sub, task, run):
    """Find the manifest row matching the given wildcards."""
    for i in range(N):
        row = row_by_id(SAMPLES, i)
        if row["sub"] == sub and row["task"] == task and row["run"] == run:
            return row
    return {}


rule confounds:
    input:
        motion=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-motion_bold.nii.gz",
        motion_params_tsv=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-motion_params.tsv",
        crop_json=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-crop.json",
    output:
        tsv=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-confounds_timeseries.tsv",
        json=f"{DERIV}/{{sub}}/func/{{sub}}_task-{{task}}_run-{{run}}_desc-confounds_timeseries.json",
    log:
        f"{LOGS}/confounds_{{sub}}_{{task}}_{{run}}.log",
    resources:
        mem_mb=500,
    run:
        import os, subprocess, json
        from pathlib import Path as _P

        # Get run info for this wildcard
        r = find_row_by_wildcards(wildcards.sub, wildcards.task, wildcards.run)
        in_bold = input.motion
        motion_params_tsv = input.motion_params_tsv

        # Read crop information from input
        crop_from = 0
        crop_to = 0
        if Path(input.crop_json).exists():
            with open(input.crop_json, "r") as f:
                crop_info = json.load(f)
                crop_from = crop_info.get("from", 0)
                crop_to = crop_info.get("to", 0)

                # Get censor configuration
        censor_cfg = CFG.get("options", {}).get("censor", {})
        censor_enable = censor_cfg.get("enable", False)

        env = os.environ.copy()
        env["IN_BOLD"] = in_bold
        env["OUT_TSV"] = output.tsv
        env["OUT_JSON"] = output.json
        env["TR_S"] = str(CFG.get("acq", {}).get("tr", 1.0))
        env["CROP_FROM"] = str(crop_from)
        env["CROP_TO"] = str(crop_to)
        env["MOTION_PARAMS_TSV"] = motion_params_tsv

        # Set censor environment variables
        env["CENSOR_ENABLE"] = "1" if censor_enable else "0"
        if censor_enable:
            env["CENSOR_FD_MM"] = str(censor_cfg.get("fd_thresh_mm", 0.5))
            env["CENSOR_DVARS"] = str(censor_cfg.get("dvars_thresh", 1.5))
            env["CENSOR_MIN_CONTIG"] = str(censor_cfg.get("min_contig_vols", 5))
            env["CENSOR_PAD"] = str(censor_cfg.get("pad_vols", 1))
        else:
            env["CENSOR_FD_MM"] = "0.5"
            env["CENSOR_DVARS"] = "1.5"
            env["CENSOR_MIN_CONTIG"] = "5"
            env["CENSOR_PAD"] = "1"

            # Get aCompCor configuration
        acompcor_cfg = CFG.get("options", {}).get("acompcor", {})
        acompcor_enable = acompcor_cfg.get("enable", False)

        # Set aCompCor environment variables
        env["ACOMPCOR_ENABLE"] = "1" if acompcor_enable else "0"
        if acompcor_enable:
            env["ACOMPCOR_TISSUES"] = ",".join(acompcor_cfg.get("tissues", []))
            env["ACOMPCOR_N"] = str(acompcor_cfg.get("n_components_per_tissue", 5))
            env["ACOMPCOR_HIGHPASS_HZ"] = str(acompcor_cfg.get("highpass_hz", 0.008))
            env["ACOMPCOR_DETREND"] = "1" if acompcor_cfg.get("detrend", True) else "0"
            env["ACOMPCOR_STANDARDIZE"] = "1" if acompcor_cfg.get("standardize", True) else "0"
        else:
            env["ACOMPCOR_TISSUES"] = "None"
            env["ACOMPCOR_N"] = "5"
            env["ACOMPCOR_HIGHPASS_HZ"] = "0.008"
            env["ACOMPCOR_DETREND"] = "1"
            env["ACOMPCOR_STANDARDIZE"] = "1"

            # Set mask paths from manifest
        env["CORD_MASK"] = r.get("deriv_cord_mask", "None") if r else "None"
        env["WM_MASK"] = r.get("deriv_wm_mask", "None") if r else "None"
        env["CSF_MASK"] = r.get("deriv_csf_mask", "None") if r else "None"
        Path("steps/spi07_confounds.sh").chmod(0o755)
        subprocess.run(["bash", "steps/spi07_confounds.sh"], check=True, env=env)

        # Provenance (one file is enough to carry .prov.json; we attach to TSV)
        write_prov(
            target=output.tsv,
            step="confounds",
            inputs={
                "IN_BOLD": in_bold,
                "MOTION_PARAMS_TSV": motion_params_tsv,
                "CROP_JSON": input.crop_json,
                "CORD_MASK": env["CORD_MASK"],
                "WM_MASK": env["WM_MASK"],
                "CSF_MASK": env["CSF_MASK"],
            },
            params={
                "TR_S": CFG.get("acq", {}).get("tr", 1.0),
                "temporal_crop": {"from": crop_from, "to": crop_to},
                "censor": {
                    "enable": censor_enable,
                    "fd_thresh_mm": censor_cfg.get("fd_thresh_mm", 0.5),
                    "dvars_thresh": censor_cfg.get("dvars_thresh", 1.5),
                    "min_contig_vols": censor_cfg.get("min_contig_vols", 5),
                    "pad_vols": censor_cfg.get("pad_vols", 1),
                },
                "acompcor": {
                    "enable": acompcor_enable,
                    "tissues": acompcor_cfg.get("tissues", []),
                    "n_components_per_tissue": acompcor_cfg.get("n_components_per_tissue", 5),
                    "highpass_hz": acompcor_cfg.get("highpass_hz", 0.008),
                    "detrend": acompcor_cfg.get("detrend", True),
                    "standardize": acompcor_cfg.get("standardize", True),
                },
            },
            tools={"step": "spi07_confounds.sh"},
        )


# QC Report generation
rule report_subject:
    output:
        html=f"{DERIV}/{{sub}}/reports/{{sub}}_desc-qc.html",
    input:
        manifest=MANIFEST_DERIV,
    params:
        sub=lambda wc: wc.sub,
    run:
        from spineprep.config import load_config

        cfg = load_config(CFG_PATH, CFG_SCHEMA)
        render_subject_report(params.sub, MANIFEST_DERIV, cfg, DERIV)


rule reports_all:
    input:
        manifest=MANIFEST_DERIV,
        reports=expand(
            f"{DERIV}/{{sub}}/reports/{{sub}}_desc-qc.html",
            sub=subjects_from_manifest(MANIFEST_DERIV) if N > 0 else [],
        ),


# deprecated: use per-run rules
rule mppca_smoke:
    input:
        disc=rules.discover.output.out,
    output:
        mark=f"{LOGS}/mppca_smoke.ok",
    run:
        import os, subprocess

        row = first_row(SAMPLES)
        in_bold = row["bold_path"]
        env = os.environ.copy()
        env["IN_BOLD"] = in_bold
        env["DENOISE_MPPCA"] = "1" if CFG.get("options", {}).get("denoise_mppca", False) else "0"
        Path("steps/spi05_mppca.sh").chmod(0o755)
        subprocess.run(["bash", "steps/spi05_mppca.sh"], check=True, env=env)
        Path(output.mark).write_text("ok\n")


rule motion_smoke:
    input:
        disc=rules.discover.output.out,
        prev=rules.mppca_smoke.output.mark,
    output:
        mark=f"{LOGS}/motion_smoke.ok",
    run:
        import os, subprocess
        from pathlib import Path as _P

        row = first_row(SAMPLES)
        in_bold = row["mppca_path"]
        if not _P(in_bold).exists():
            in_bold = row["bold_path"]
        env = os.environ.copy()
        env["IN_BOLD"] = in_bold
        env["MOTION_ENABLE"] = "1"
        Path("steps/spi06_motion.sh").chmod(0o755)
        subprocess.run(["bash", "steps/spi06_motion.sh"], check=True, env=env)
        Path(output.mark).write_text("ok\n")


rule confounds_smoke:
    input:
        prev=rules.motion_smoke.output.mark,
    output:
        mark=f"{LOGS}/confounds_smoke.ok",
    run:
        import os, subprocess
        from pathlib import Path as _P

        row = first_row(SAMPLES)
        in_bold = row["motion_path"]
        if not _P(in_bold).exists():
            in_bold = row["bold_path"]
        env = os.environ.copy()
        env["IN_BOLD"] = in_bold
        env["TR_S"] = str(CFG.get("acq", {}).get("tr", 1.0))
        Path("steps/spi07_confounds.sh").chmod(0o755)
        subprocess.run(["bash", "steps/spi07_confounds.sh"], check=True, env=env)
        Path(output.mark).write_text("ok\n")


# Registration rules (conditional on config)
# Only run if registration is enabled
if CFG.get("registration", {}).get("enable", False):

    rule epi_mean:
        output:
            mean=expand(
                "{epi_mean}",
                epi_mean=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["epi_mean"]
                    for i in range(N)
                ],
            ),
        run:
            import os, subprocess

            for i in range(N):
                r = row_by_id(SAMPLES, i)
                rD = row_by_id(MANIFEST_DERIV, i)
                targets = derive_outputs(rD, DERIV)
                in_bold = r["bold_path"]
                out_mean = targets["epi_mean"]

                # Create output directory
                Path(out_mean).parent.mkdir(parents=True, exist_ok=True)

                # Compute mean using fslmaths or fallback
                import shutil

                if shutil.which("fslmaths"):
                    try:
                        subprocess.run(["fslmaths", in_bold, "-Tmean", out_mean], check=True)
                    except subprocess.CalledProcessError:
                        # Fallback: copy input file if fslmaths fails
                        subprocess.run(["cp", in_bold, out_mean], check=True)
                else:
                    # Fallback: copy first volume
                    subprocess.run(["cp", in_bold, out_mean], check=True)

    rule seg_cord:
        input:
            epi_mean=expand(
                "{epi_mean}",
                epi_mean=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["epi_mean"]
                    for i in range(N)
                ],
            ),
        output:
            cordmask=expand(
                "{cordmask_seg}",
                cordmask_seg=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["cordmask_seg"]
                    for i in range(N)
                ],
            ),
        run:
            import os, subprocess

            for i in range(N):
                r = row_by_id(SAMPLES, i)
                rD = row_by_id(MANIFEST_DERIV, i)
                epi_path, t2_path = derive_inputs(rD, BIDS)

                if not t2_path:
                    # Fallback to EPI mean
                    t2_path = epi_path

                out_cordmask = derive_outputs(rD, DERIV)["cordmask_seg"]

                env = os.environ.copy()
                env["IN_T2"] = t2_path
                env["OUT_CORDMASK"] = out_cordmask
                Path("steps/spi10_seg_cord.sh").chmod(0o755)
                subprocess.run(["bash", "steps/spi10_seg_cord.sh"], check=True, env=env)

    rule label_levels:
        input:
            cordmask=expand(
                "{cordmask_seg}",
                cordmask_seg=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["cordmask_seg"]
                    for i in range(N)
                ],
            ),
        output:
            levels=expand(
                "{levels_native}",
                levels_native=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["levels_native"]
                    for i in range(N)
                ],
            ),
        run:
            import os, subprocess

            for i in range(N):
                rD = row_by_id(MANIFEST_DERIV, i)
                targets = derive_outputs(rD, DERIV)

                in_cordmask = targets["cordmask_seg"]
                out_levels = targets["levels_native"]

                env = os.environ.copy()
                env["IN_CORDMASK"] = in_cordmask
                env["OUT_LEVELS"] = out_levels
                Path("steps/spi11_label_levels.sh").chmod(0o755)
                subprocess.run(["bash", "steps/spi11_label_levels.sh"], check=True, env=env)

    rule reg_epi2t2:
        input:
            epi_mean=expand(
                "{epi_mean}",
                epi_mean=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["epi_mean"]
                    for i in range(N)
                ],
            ),
            cordmask=expand(
                "{cordmask_seg}",
                cordmask_seg=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["cordmask_seg"]
                    for i in range(N)
                ],
            ),
        output:
            warp=expand(
                "{warp_epi2t2}",
                warp_epi2t2=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["warp_epi2t2"]
                    for i in range(N)
                ],
            ),
            epi_in_t2=expand(
                "{epi_in_t2}",
                epi_in_t2=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["epi_in_t2"]
                    for i in range(N)
                ],
            ),
        run:
            import os, subprocess

            for i in range(N):
                r = row_by_id(SAMPLES, i)
                rD = row_by_id(MANIFEST_DERIV, i)
                epi_path, t2_path = derive_inputs(rD, BIDS)

                if not t2_path:
                    # Fallback to EPI mean
                    t2_path = epi_path

                targets = derive_outputs(rD, DERIV)
                in_epi = epi_path
                out_warp = targets["warp_epi2t2"]
                out_epi_in_t2 = targets["epi_in_t2"]

                env = os.environ.copy()
                env["IN_EPI"] = in_epi
                env["IN_T2"] = t2_path
                env["OUT_WARP"] = out_warp
                env["OUT_EPI_IN_T2"] = out_epi_in_t2
                Path("steps/spi12_reg_epi2t2.sh").chmod(0o755)
                subprocess.run(["bash", "steps/spi12_reg_epi2t2.sh"], check=True, env=env)

    rule reg_t22pam50:
        input:
            warp_epi2t2=expand(
                "{warp_epi2t2}",
                warp_epi2t2=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["warp_epi2t2"]
                    for i in range(N)
                ],
            ),
        output:
            warp=expand(
                "{warp_t22pam50}",
                warp_t22pam50=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["warp_t22pam50"]
                    for i in range(N)
                ],
            ),
            t2_in_pam50=expand(
                "{t2_in_pam50}",
                t2_in_pam50=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["t2_in_pam50"]
                    for i in range(N)
                ],
            ),
        run:
            import os, subprocess

            for i in range(N):
                r = row_by_id(SAMPLES, i)
                rD = row_by_id(MANIFEST_DERIV, i)
                epi_path, t2_path = derive_inputs(rD, BIDS)

                if not t2_path:
                    # Fallback to EPI mean
                    t2_path = epi_path

                targets = derive_outputs(rD, DERIV)
                out_warp = targets["warp_t22pam50"]
                out_t2_in_pam50 = targets["t2_in_pam50"]

                env = os.environ.copy()
                env["IN_T2"] = t2_path
                env["OUT_WARP"] = out_warp
                env["OUT_T2_IN_PAM50"] = out_t2_in_pam50
                Path("steps/spi13_reg_t22pam50.sh").chmod(0o755)
                subprocess.run(["bash", "steps/spi13_reg_t22pam50.sh"], check=True, env=env)

    rule warp_masks:
        input:
            cordmask_native=expand(
                "{cordmask_seg}",
                cordmask_seg=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["cordmask_seg"]
                    for i in range(N)
                ],
            ),
            warp_epi2t2=expand(
                "{warp_epi2t2}",
                warp_epi2t2=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["warp_epi2t2"]
                    for i in range(N)
                ],
            ),
            warp_t22pam50=expand(
                "{warp_t22pam50}",
                warp_t22pam50=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["warp_t22pam50"]
                    for i in range(N)
                ],
            ),
        output:
            cordmask_native=expand(
                "{cordmask_native_final}",
                cordmask_native_final=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["mask_native_cord"]
                    for i in range(N)
                ],
            ),
            cordmask_pam50=expand(
                "{cordmask_pam50}",
                cordmask_pam50=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["mask_pam50_cord"]
                    for i in range(N)
                ],
            ),
            wmmask_native=expand(
                "{wmmask_native}",
                wmmask_native=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["mask_native_wm"]
                    for i in range(N)
                ],
            ),
            wmmask_pam50=expand(
                "{wmmask_pam50}",
                wmmask_pam50=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["mask_pam50_wm"]
                    for i in range(N)
                ],
            ),
            csfmask_native=expand(
                "{csfmask_native}",
                csfmask_native=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["mask_native_csf"]
                    for i in range(N)
                ],
            ),
            csfmask_pam50=expand(
                "{csfmask_pam50}",
                csfmask_pam50=[
                    derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["mask_pam50_csf"]
                    for i in range(N)
                ],
            ),
        run:
            import os, subprocess

            for i in range(N):
                rD = row_by_id(MANIFEST_DERIV, i)
                targets = derive_outputs(rD, DERIV)

                in_cordmask_native = targets["cordmask_seg"]
                in_warp_epi2t2 = targets["warp_epi2t2"]
                in_warp_t22pam50 = targets["warp_t22pam50"]

                out_cordmask_native = targets["mask_native_cord"]
                out_cordmask_pam50 = targets["mask_pam50_cord"]
                out_wmmask_native = targets["mask_native_wm"]
                out_wmmask_pam50 = targets["mask_pam50_wm"]
                out_csfmask_native = targets["mask_native_csf"]
                out_csfmask_pam50 = targets["mask_pam50_csf"]

                env = os.environ.copy()
                env["IN_CORDMASK_NATIVE"] = in_cordmask_native
                env["IN_WARP_EPI2T2"] = in_warp_epi2t2
                env["IN_WARP_T22PAM50"] = in_warp_t22pam50
                env["OUT_CORDMASK_NATIVE"] = out_cordmask_native
                env["OUT_CORDMASK_PAM50"] = out_cordmask_pam50
                env["OUT_WMMASK_NATIVE"] = out_wmmask_native
                env["OUT_WMMASK_PAM50"] = out_wmmask_pam50
                env["OUT_CSFMASK_NATIVE"] = out_csfmask_native
                env["OUT_CSFMASK_PAM50"] = out_csfmask_pam50
                Path("steps/spi14_warp_masks.sh").chmod(0o755)
                subprocess.run(["bash", "steps/spi14_warp_masks.sh"], check=True, env=env)

    rule registration_all:
        input:
            manifest=MANIFEST_DERIV,
            # All mask outputs from warp_masks rule
            cordmask_pam50=expand(
                "{cordmask_pam50}",
                cordmask_pam50=(
                    [
                        derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["mask_pam50_cord"]
                        for i in range(N)
                    ]
                    if N > 0
                    else []
                ),
            ),
            wmmask_pam50=expand(
                "{wmmask_pam50}",
                wmmask_pam50=(
                    [
                        derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["mask_pam50_wm"]
                        for i in range(N)
                    ]
                    if N > 0
                    else []
                ),
            ),
            csfmask_pam50=expand(
                "{csfmask_pam50}",
                csfmask_pam50=(
                    [
                        derive_outputs(row_by_id(MANIFEST_DERIV, i), DERIV)["mask_pam50_csf"]
                        for i in range(N)
                    ]
                    if N > 0
                    else []
                ),
            ),
        run:
            # This rule just aggregates the registration outputs
            print(f"Registration completed for {N} runs")
